{
    "sourceFile": "flatter/client.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 126,
            "patches": [
                {
                    "date": 1717946305598,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1717946368265,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -403,6 +403,6 @@\n     grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n     print(grouped)\r\n \r\n if __name__ == '__main__':\r\n-    client_reddit()\r\n+    # client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717946381809,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -310,99 +310,99 @@\n \r\n     # # #GROUP BY\r\n     # print(pa.TableGroupBy(main_data,'year'))\r\n \r\n-    genres_row_number=genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n \r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table.group_by('first_value'))\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n \r\n-    genres_row_number = genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    second_values_array = pa.array(second_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    print(grouped_table)\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n \r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n \r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table.group_by('first_value'))\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n \r\n-    # #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n     \r\n-    genres_row_number=genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n\\ No newline at end of file\n-            aggregated_values[row_number].extend(value_list)\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n \r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n     \r\n-    genres_row_number = genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    second_values_array = pa.array(second_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n \r\n \r\n-    unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    grouped_data = {'row_number': [], 'value': []}\r\n-    for row_num in unique_row_numbers:\r\n-        mask = pc.equal(genres_data['row_number'], row_num)\r\n-        filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-        grouped_data['row_number'].append(row_num.as_py())\r\n-        grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    grouped_table = pa.table(grouped_data)\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n     \r\n-    genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    data_with_strings = pa.table({'genres': genres_as_string})\r\n-    grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    print(grouped)\r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     # client_reddit()\r\n-    # client_example()\n+    client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717946388359,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -221,23 +221,23 @@\n     # data_with_strings = pa.table({'genres': genres_as_string})\r\n     # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n     # print(grouped)\r\n     \r\n-    port = 50053\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     \r\n-    main_table_name = 'TablesMethod_movies'\r\n-    cast_table_name = 'TablesMethod_movies_cast'\r\n-    genres_table_name = 'TablesMethod_movies_genres'\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n     \r\n-    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    main_data = reader.read_all()\r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n     \r\n-    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    cast_data = reader.read_all()\r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n     \r\n-    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    genres_data = reader.read_all()\r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n     \r\n     # print(main_data)\r\n     # print(cast_data)\r\n     # print(genres_data)\r\n"
                },
                {
                    "date": 1717946398107,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,407 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    \r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # print(main_data)\r\n+    # print(cast_data)\r\n+    # print(genres_data)\r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    # client_reddit()\r\n+    client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717946409099,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,437 +16,29 @@\n             print(f\"Data from table {port}:: '{table_name}':\")\r\n             # print(data)\r\n #Movies\r\n def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'FlattenedJSON_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n     # SELECTION\r\n     # first level query\r\n     ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n \r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    \r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # print(main_data)\r\n-    # print(cast_data)\r\n-    # print(genres_data)\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n     # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    # client_reddit()\r\n-    client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n     # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n \r\n     # # #SORT\r\n     # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n"
                },
                {
                    "date": 1717946552771,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,407 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    \r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # print(main_data)\r\n+    # print(cast_data)\r\n+    # print(genres_data)\r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    # client_reddit()\r\n+    client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717946569754,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,406 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # print(main_data)\r\n+    # print(cast_data)\r\n+    # print(genres_data)\r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    # client_reddit()\r\n+    client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717946577975,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -220,841 +220,27 @@\n     # data_with_strings = pa.table({'genres': genres_as_string})\r\n     # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n     # print(grouped)\r\n     \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # print(main_data)\r\n-    # print(cast_data)\r\n-    # print(genres_data)\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    # client_reddit()\r\n-    client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    \r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # print(main_data)\r\n-    # print(cast_data)\r\n-    # print(genres_data)\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    # client_reddit()\r\n-    client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n+    port = 50053\r\n     client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedJSON_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n+    main_table_name = 'TablesMethod_movies'\r\n+    cast_table_name = 'TablesMethod_movies_cast'\r\n+    genres_table_name = 'TablesMethod_movies_genres'\r\n     \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n+    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    main_data = reader.read_all()\r\n     \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n+    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    cast_data = reader.read_all()\r\n     \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n+    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    genres_data = reader.read_all()\r\n     \r\n+    print(main_data)\r\n+    print(cast_data)\r\n+    print(genres_data)\r\n     \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    \r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # print(main_data)\r\n-    # print(cast_data)\r\n-    # print(genres_data)\r\n-    \r\n     # SELECTION\r\n     # first level query\r\n     ## to string\r\n     # print(main_data.select(['title']))\r\n"
                },
                {
                    "date": 1717949815060,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,406 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    port = 50053\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    main_table_name = 'TablesMethod_movies'\r\n+    cast_table_name = 'TablesMethod_movies_cast'\r\n+    genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    main_data = reader.read_all()\r\n+    \r\n+    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    cast_data = reader.read_all()\r\n+    \r\n+    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    genres_data = reader.read_all()\r\n+    \r\n+    print(main_data)\r\n+    print(cast_data)\r\n+    print(genres_data)\r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    # client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717949868403,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,403 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    port = 50053\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    main_table_name = 'TablesMethod_movies'\r\n+    cast_table_name = 'TablesMethod_movies_cast'\r\n+    genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    main_data = reader.read_all()\r\n+    \r\n+    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    cast_data = reader.read_all()\r\n+    \r\n+    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    genres_data = reader.read_all()\r\n+    \r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717949878906,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -235,857 +235,44 @@\n     \r\n     reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n     genres_data = reader.read_all()\r\n     \r\n-    \r\n     # SELECTION\r\n     # first level query\r\n-    ## to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n+    # to string\r\n+    print(main_data.select(['title']))\r\n+    ## to int\r\n+    print(main_data.select(['year']))\r\n     # ## object from list \r\n     # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    port = 50053\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    main_table_name = 'TablesMethod_movies'\r\n-    cast_table_name = 'TablesMethod_movies_cast'\r\n-    genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    main_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    cast_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    genres_data = reader.read_all()\r\n-    \r\n-    print(main_data)\r\n     print(cast_data)\r\n-    print(genres_data)\r\n     \r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n+    grouped_table = cast_data.group_by('row_number')\r\n \r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n \r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    print(result_table)\r\n \r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    # client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n     # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n \r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    port = 50053\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    main_table_name = 'TablesMethod_movies'\r\n-    cast_table_name = 'TablesMethod_movies_cast'\r\n-    genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    main_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    cast_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    genres_data = reader.read_all()\r\n-    \r\n-    print(main_data)\r\n-    print(cast_data)\r\n-    print(genres_data)\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n     # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n     # tenth_values_array  = pa.array(tenth_values )\r\n     # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n     # print(result_table)\r\n@@ -1210,6 +397,6 @@\n     # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n-    # client_reddit()\r\n-    client_example()\n\\ No newline at end of file\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717949895278,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    port = 50053\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    main_table_name = 'TablesMethod_movies'\r\n+    cast_table_name = 'TablesMethod_movies_cast'\r\n+    genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    main_data = reader.read_all()\r\n+    \r\n+    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    cast_data = reader.read_all()\r\n+    \r\n+    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    genres_data = reader.read_all()\r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    # to string\r\n+    print(main_data.select(['title']))\r\n+    ## to int\r\n+    print(main_data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    print(cast_data)\r\n+    \r\n+    grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    print(result_table)\r\n+\r\n+    # ### medium level of nulls\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    tenth_values_array  = pa.array(tenth_values )\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    print(result_table)\r\n+    \r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    tenth_values_array  = pa.array(tenth_values )\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    print(result_table)\r\n+    \r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717949919016,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -304,368 +304,38 @@\n \r\n     # #GROUP BY\r\n     print(pa.TableGroupBy(main_data,'year'))\r\n \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    port = 50053\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    main_table_name = 'TablesMethod_movies'\r\n-    cast_table_name = 'TablesMethod_movies_cast'\r\n-    genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    main_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    cast_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    genres_data = reader.read_all()\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    # to string\r\n-    print(main_data.select(['title']))\r\n-    ## to int\r\n-    print(main_data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    print(cast_data)\r\n-    \r\n-    grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    genres_row_number=genres_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n     aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n         if row_number not in aggregated_values:\r\n             aggregated_values[row_number] = value_list\r\n         else:\r\n             aggregated_values[row_number].extend(value_list)\r\n \r\n     first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n     first_values_array = pa.array(first_values)\r\n     result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table)\r\n+    print(result_table.group_by('first_value'))\r\n \r\n-    # ### medium level of nulls\r\n+    genres_row_number = genres_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    second_values_array = pa.array(second_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    print(grouped_table)\r\n+\r\n     cast_row_number=cast_data['row_number']\r\n     split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n     aggregated_values = {}\r\n     for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n@@ -673,85 +343,13 @@\n             aggregated_values[row_number] = value_list\r\n         else:\r\n             aggregated_values[row_number].extend(value_list)\r\n \r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n     # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n     # first_values_array = pa.array(first_values)\r\n     # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n     # print(result_table.group_by('first_value'))\r\n \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n     # # #AGGREGATE FUNCTION\r\n     # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n     \r\n     # genres_row_number=genres_data['row_number']\r\n"
                },
                {
                    "date": 1717949933999,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    port = 50053\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    main_table_name = 'TablesMethod_movies'\r\n+    cast_table_name = 'TablesMethod_movies_cast'\r\n+    genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    main_data = reader.read_all()\r\n+    \r\n+    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    cast_data = reader.read_all()\r\n+    \r\n+    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    genres_data = reader.read_all()\r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    # to string\r\n+    print(main_data.select(['title']))\r\n+    ## to int\r\n+    print(main_data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    print(cast_data)\r\n+    \r\n+    grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    print(result_table)\r\n+\r\n+    # ### medium level of nulls\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    tenth_values_array  = pa.array(tenth_values )\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    print(result_table)\r\n+    \r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    tenth_values_array  = pa.array(tenth_values )\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    print(result_table)\r\n+    \r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    genres_row_number=genres_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    print(result_table.group_by('first_value'))\r\n+\r\n+    genres_row_number = genres_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    second_values_array = pa.array(second_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    print(grouped_table)\r\n+\r\n+    cast_row_number=cast_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    print(result_table.group_by('first_value'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    genres_row_number=genres_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    genres_row_number = genres_data['row_number']\r\n+    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    aggregated_values = {}\r\n+    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+        if row_number not in aggregated_values:\r\n+            aggregated_values[row_number] = value_list\r\n+        else:\r\n+            aggregated_values[row_number].extend(value_list)\r\n+    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    first_values_array = pa.array(first_values)\r\n+    second_values_array = pa.array(second_values)\r\n+    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    grouped_data = {'row_number': [], 'value': []}\r\n+    for row_num in unique_row_numbers:\r\n+        mask = pc.equal(genres_data['row_number'], row_num)\r\n+        filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+        grouped_data['row_number'].append(row_num.as_py())\r\n+        grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    grouped_table = pa.table(grouped_data)\r\n+    \r\n+    genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    data_with_strings = pa.table({'genres': genres_as_string})\r\n+    grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717949960330,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950043290,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,13 +115,13 @@\n     # combined_df = pa.concat_tables(combined_df)\r\n     # combined_df = combined_df.combine_chunks()\r\n     # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n \r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n+    port = 50052\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'FlattenedJSON_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n \r\n     # SELECTION\r\n     # first level query\r\n     ## to string\r\n@@ -398,809 +398,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    port = 50053\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    main_table_name = 'TablesMethod_movies'\r\n-    cast_table_name = 'TablesMethod_movies_cast'\r\n-    genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    main_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    cast_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    genres_data = reader.read_all()\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    # to string\r\n-    print(main_data.select(['title']))\r\n-    ## to int\r\n-    print(main_data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    print(cast_data)\r\n-    \r\n-    grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table)\r\n-\r\n-    # ### medium level of nulls\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    tenth_values_array  = pa.array(tenth_values )\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    print(result_table)\r\n-    \r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    tenth_values_array  = pa.array(tenth_values )\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    print(result_table)\r\n-    \r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    genres_row_number=genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table.group_by('first_value'))\r\n-\r\n-    genres_row_number = genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    second_values_array = pa.array(second_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    print(grouped_table)\r\n-\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table.group_by('first_value'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    genres_row_number=genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    genres_row_number = genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    second_values_array = pa.array(second_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    grouped_data = {'row_number': [], 'value': []}\r\n-    for row_num in unique_row_numbers:\r\n-        mask = pc.equal(genres_data['row_number'], row_num)\r\n-        filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-        grouped_data['row_number'].append(row_num.as_py())\r\n-        grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    grouped_table = pa.table(grouped_data)\r\n-    \r\n-    genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    data_with_strings = pa.table({'genres': genres_as_string})\r\n-    grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    port = 50053\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    main_table_name = 'TablesMethod_movies'\r\n-    cast_table_name = 'TablesMethod_movies_cast'\r\n-    genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    main_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    cast_data = reader.read_all()\r\n-    \r\n-    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    genres_data = reader.read_all()\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    # to string\r\n-    print(main_data.select(['title']))\r\n-    ## to int\r\n-    print(main_data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    print(cast_data)\r\n-    \r\n-    grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table)\r\n-\r\n-    # ### medium level of nulls\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    tenth_values_array  = pa.array(tenth_values )\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    print(result_table)\r\n-    \r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    tenth_values_array  = pa.array(tenth_values )\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    print(result_table)\r\n-    \r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    genres_row_number=genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    print(result_table.group_by('first_value'))\r\n-\r\n-    genres_row_number = genres_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    first_values_array = pa.array(first_values)\r\n-    second_values_array = pa.array(second_values)\r\n-    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    print(grouped_table)\r\n-\r\n-    cast_row_number=cast_data['row_number']\r\n-    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    aggregated_values = {}\r\n-    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-        if row_number not in aggregated_values:\r\n-            aggregated_values[row_number] = value_list\r\n-        else:\r\n-            aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950072871,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,13 +115,13 @@\n     # combined_df = pa.concat_tables(combined_df)\r\n     # combined_df = combined_df.combine_chunks()\r\n     # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n \r\n-    port = 50052\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedJSON_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n \r\n     # SELECTION\r\n     # first level query\r\n     ## to string\r\n"
                },
                {
                    "date": 1717950094740,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,27 +16,27 @@\n             print(f\"Data from table {port}:: '{table_name}':\")\r\n             # print(data)\r\n #Movies\r\n def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'FlattenedJSON_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n \r\n     # # # FILTRES\r\n     # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n \r\n"
                },
                {
                    "date": 1717950108861,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950124226,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950138283,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'JSONPath_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950187098,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,780 +67,27 @@\n     # print(combined_df)\r\n     # combined_df = combined_df.combine_chunks()\r\n     # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n \r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n+    port = 50054\r\n     client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n+    table_name = 'SimpleMethod_movies'\r\n     reader = client.do_get(flight.Ticket(table_name.encode()))\r\n     data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n     \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n     # SELECTION\r\n     # first level query\r\n     ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n     print(data.select(['title']))\r\n     ## to int\r\n     print(data.select(['year']))\r\n     ## object from list \r\n     ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n+    print(data.select(['cast_0']))\r\n+    # ### medium level of nulls\r\n+    print(data.select(['cast_9']))\r\n+    # ### high level of nulls - last element of list\r\n+    print(data.select(['cast_58']))\r\n \r\n     # # # FILTRES\r\n     # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n \r\n@@ -850,59 +97,8 @@\n     # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n \r\n     # #GROUP BY\r\n     # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n     # print(pa.TableGroupBy(data,'genres_0'))\r\n     # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n     # print(pa.TableGroupBy(data,'cast_0'))\r\n \r\n@@ -1202,407 +398,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedJSON_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950196092,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'JSONPath_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    port = 50054\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'SimpleMethod_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast_0']))\r\n+    # ### medium level of nulls\r\n+    print(data.select(['cast_9']))\r\n+    # ### high level of nulls - last element of list\r\n+    print(data.select(['cast_58']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres_0'))\r\n+    print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950207651,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,378 +67,27 @@\n     # print(combined_df)\r\n     # combined_df = combined_df.combine_chunks()\r\n     # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n \r\n-    port = 50054\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'SimpleMethod_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast_0']))\r\n-    # ### medium level of nulls\r\n-    print(data.select(['cast_9']))\r\n-    # ### high level of nulls - last element of list\r\n-    print(data.select(['cast_58']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres_0'))\r\n-    print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n+    # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n+    # table_name = 'SimpleMethod_movies'\r\n     # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n     # data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n     \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n     # # SELECTION\r\n     # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'JSONPath_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n     # ## to string\r\n     # print(data.select(['title']))\r\n     # ## to int\r\n     # print(data.select(['year']))\r\n     # ## object from list \r\n     # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n \r\n     # # # FILTRES\r\n     # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n \r\n@@ -448,59 +97,8 @@\n     # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n \r\n     # #GROUP BY\r\n     # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    port = 50054\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'SimpleMethod_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast_0']))\r\n-    # ### medium level of nulls\r\n-    print(data.select(['cast_9']))\r\n-    # ### high level of nulls - last element of list\r\n-    print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n     # print(pa.TableGroupBy(data,'genres_0'))\r\n     # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n     # print(pa.TableGroupBy(data,'cast_0'))\r\n \r\n"
                },
                {
                    "date": 1717950232378,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,13 +115,13 @@\n     # combined_df = pa.concat_tables(combined_df)\r\n     # combined_df = combined_df.combine_chunks()\r\n     # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n \r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n+    port = 50052\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'FlattenedJSON_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n \r\n     # SELECTION\r\n     # first level query\r\n     ## to string\r\n"
                },
                {
                    "date": 1717950242317,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -117,9 +117,9 @@\n     # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n \r\n     port = 50052\r\n     client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedJSON_movies'\r\n+    table_name = 'FlattenedFirstJSON_movies'\r\n     reader = client.do_get(flight.Ticket(table_name.encode()))\r\n     data = reader.read_all()\r\n \r\n     # SELECTION\r\n"
                },
                {
                    "date": 1717950251380,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -123,37 +123,37 @@\n     data = reader.read_all()\r\n \r\n     # SELECTION\r\n     # first level query\r\n-    ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+    # to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    # object from list \r\n+    ### low level of nulls - first element of list\r\n+    cast_column=data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    first_elements = []\r\n+    for row in cast_list:\r\n+        if row:  # Check if the list is not empty\r\n+            first_elements.append(row[0])\r\n+        else:\r\n+            first_elements.append(None)\r\n+    first_elements_column = pa.array(first_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n \r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+    print(new_table.select(['cast']))\r\n+    # # ### medium level of nulls\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 10:\r\n+            tenth_elements.append(row[9])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n \r\n     # print(new_table.select(['cast']))\r\n     # # # ### high level of nulls - last element of list\r\n     # cast_column = data['cast']\r\n"
                },
                {
                    "date": 1717950265571,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'JSONPath_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    port = 50052\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'FlattenedFirstJSON_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    # to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    # object from list \r\n+    ### low level of nulls - first element of list\r\n+    cast_column=data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    first_elements = []\r\n+    for row in cast_list:\r\n+        if row:  # Check if the list is not empty\r\n+            first_elements.append(row[0])\r\n+        else:\r\n+            first_elements.append(None)\r\n+    first_elements_column = pa.array(first_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+    # # ### medium level of nulls\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 10:\r\n+            tenth_elements.append(row[9])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+    # # ### high level of nulls - last element of list\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 59:\r\n+            tenth_elements.append(row[58])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+\r\n+    # # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    genres_column = data['genres']\r\n+    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    grouped_table = first_genre_table.group_by('first_genre')\r\n+    print(grouped_table)\r\n+    \r\n+    \r\n+    genres_column = data['genres']\r\n+    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    print(grouped_table)\r\n+\r\n+    cast_column = data['cast']\r\n+    first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    grouped_table = first_cast_table.group_by('first_cast')\r\n+    print(grouped_table)\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    genres_column = data['genres']\r\n+    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    grouped_table = first_genre_table.group_by('first_genre')\r\n+    print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    data_with_strings = pa.table({'genres': genres_as_string})\r\n+    grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950291008,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -218,9 +218,9 @@\n     \r\n     genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n     data_with_strings = pa.table({'genres': genres_as_string})\r\n     grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n+    print(grouped)\r\n     \r\n     # port = 50053\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # main_table_name = 'TablesMethod_movies'\r\n@@ -398,407 +398,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'JSONPath_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    port = 50052\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedFirstJSON_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    # to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    # object from list \r\n-    ### low level of nulls - first element of list\r\n-    cast_column=data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    first_elements = []\r\n-    for row in cast_list:\r\n-        if row:  # Check if the list is not empty\r\n-            first_elements.append(row[0])\r\n-        else:\r\n-            first_elements.append(None)\r\n-    first_elements_column = pa.array(first_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### medium level of nulls\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 10:\r\n-            tenth_elements.append(row[9])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950379706,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,402 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'JSONPath_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    port = 50052\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'FlattenedFirstJSON_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    # to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    # object from list \r\n+    ### low level of nulls - first element of list\r\n+    cast_column=data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    first_elements = []\r\n+    for row in cast_list:\r\n+        if row:  # Check if the list is not empty\r\n+            first_elements.append(row[0])\r\n+        else:\r\n+            first_elements.append(None)\r\n+    first_elements_column = pa.array(first_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+    # # ### medium level of nulls\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 10:\r\n+            tenth_elements.append(row[9])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+    # # ### high level of nulls - last element of list\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 59:\r\n+            tenth_elements.append(row[58])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+\r\n+    # # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    genres_column = data['genres']\r\n+    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    grouped_table = first_genre_table.group_by('first_genre')\r\n+    print(grouped_table)\r\n+    \r\n+    \r\n+    genres_column = data['genres']\r\n+    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    print(grouped_table)\r\n+\r\n+    cast_column = data['cast']\r\n+    first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    grouped_table = first_cast_table.group_by('first_cast')\r\n+    print(grouped_table)\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950420660,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -201,9 +201,9 @@\n     print(grouped_table)\r\n \r\n     #AGGREGATE FUNCTION\r\n     print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n     \r\n     # genres_column = data['genres']\r\n     # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n     # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n@@ -398,407 +398,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'JSONPath_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    port = 50052\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedFirstJSON_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    # to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    # object from list \r\n-    ### low level of nulls - first element of list\r\n-    cast_column=data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    first_elements = []\r\n-    for row in cast_list:\r\n-        if row:  # Check if the list is not empty\r\n-            first_elements.append(row[0])\r\n-        else:\r\n-            first_elements.append(None)\r\n-    first_elements_column = pa.array(first_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### medium level of nulls\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 10:\r\n-            tenth_elements.append(row[9])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### high level of nulls - last element of list\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 59:\r\n-            tenth_elements.append(row[58])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-\r\n-    # # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    genres_column = data['genres']\r\n-    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    grouped_table = first_genre_table.group_by('first_genre')\r\n-    print(grouped_table)\r\n-    \r\n-    \r\n-    genres_column = data['genres']\r\n-    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    print(grouped_table)\r\n-\r\n-    cast_column = data['cast']\r\n-    first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    grouped_table = first_cast_table.group_by('first_cast')\r\n-    print(grouped_table)\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n-    genres_column = data['genres']\r\n-    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    grouped_table = first_genre_table.group_by('first_genre')\r\n-    print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    data_with_strings = pa.table({'genres': genres_as_string})\r\n-    grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950448672,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,401 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'JSONPath_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    port = 50052\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'FlattenedFirstJSON_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    # to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    # object from list \r\n+    ### low level of nulls - first element of list\r\n+    cast_column=data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    first_elements = []\r\n+    for row in cast_list:\r\n+        if row:  # Check if the list is not empty\r\n+            first_elements.append(row[0])\r\n+        else:\r\n+            first_elements.append(None)\r\n+    first_elements_column = pa.array(first_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+    # # ### medium level of nulls\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 10:\r\n+            tenth_elements.append(row[9])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+    # # ### high level of nulls - last element of list\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 59:\r\n+            tenth_elements.append(row[58])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+\r\n+    # # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    genres_column = data['genres']\r\n+    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    grouped_table = first_genre_table.group_by('first_genre')\r\n+    print(grouped_table)\r\n+    \r\n+    \r\n+    genres_column = data['genres']\r\n+    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    print(grouped_table)\r\n+\r\n+    cast_column = data['cast']\r\n+    first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    grouped_table = first_cast_table.group_by('first_cast')\r\n+    print(grouped_table)\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950463158,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,401 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    # port = 50051\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'JSONPath_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast[0]']))\r\n+    # ### medium level of nulls\r\n+    # print(data.select(['cast[9]']))\r\n+    # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast[58]']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres[0]'))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+    #     print(genre)\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # print(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    port = 50052\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'FlattenedFirstJSON_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    # to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    # object from list \r\n+    ### low level of nulls - first element of list\r\n+    cast_column=data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    first_elements = []\r\n+    for row in cast_list:\r\n+        if row:  # Check if the list is not empty\r\n+            first_elements.append(row[0])\r\n+        else:\r\n+            first_elements.append(None)\r\n+    first_elements_column = pa.array(first_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+    # # ### medium level of nulls\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 10:\r\n+            tenth_elements.append(row[9])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+    # # ### high level of nulls - last element of list\r\n+    cast_column = data['cast']\r\n+    cast_list = cast_column.to_pylist()\r\n+    tenth_elements = []\r\n+    for row in cast_list:\r\n+        if len(row) >= 59:\r\n+            tenth_elements.append(row[58])\r\n+        else:\r\n+            tenth_elements.append(None)\r\n+    tenth_elements_column = pa.array(tenth_elements)\r\n+    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    print(new_table.select(['cast']))\r\n+\r\n+    # # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    genres_column = data['genres']\r\n+    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    grouped_table = first_genre_table.group_by('first_genre')\r\n+    print(grouped_table)\r\n+    \r\n+    \r\n+    genres_column = data['genres']\r\n+    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    print(grouped_table)\r\n+\r\n+    cast_column = data['cast']\r\n+    first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    grouped_table = first_cast_table.group_by('first_cast')\r\n+    print(grouped_table)\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    genres_column = data['genres']\r\n+    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    grouped_table = first_genre_table.group_by('first_genre')\r\n+    print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    data_with_strings = pa.table({'genres': genres_as_string})\r\n+    grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950476838,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,898 +115,95 @@\n     # combined_df = pa.concat_tables(combined_df)\r\n     # combined_df = combined_df.combine_chunks()\r\n     # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n \r\n-    port = 50052\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedFirstJSON_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    # to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    # object from list \r\n-    ### low level of nulls - first element of list\r\n-    cast_column=data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    first_elements = []\r\n-    for row in cast_list:\r\n-        if row:  # Check if the list is not empty\r\n-            first_elements.append(row[0])\r\n-        else:\r\n-            first_elements.append(None)\r\n-    first_elements_column = pa.array(first_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### medium level of nulls\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 10:\r\n-            tenth_elements.append(row[9])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### high level of nulls - last element of list\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 59:\r\n-            tenth_elements.append(row[58])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-\r\n-    # # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    genres_column = data['genres']\r\n-    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    grouped_table = first_genre_table.group_by('first_genre')\r\n-    print(grouped_table)\r\n-    \r\n-    \r\n-    genres_column = data['genres']\r\n-    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    print(grouped_table)\r\n-\r\n-    cast_column = data['cast']\r\n-    first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    grouped_table = first_cast_table.group_by('first_cast')\r\n-    print(grouped_table)\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    genres_column = data['genres']\r\n-    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    grouped_table = first_genre_table.group_by('first_genre')\r\n-    print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    data_with_strings = pa.table({'genres': genres_as_string})\r\n-    grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    print(grouped)\r\n-    \r\n-    # port = 50053\r\n+    # port = 50052\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'JSONPath_movies'\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n     # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n     # data = reader.read_all()\r\n \r\n     # # SELECTION\r\n     # # first level query\r\n-    # ## to string\r\n+    # # to string\r\n     # print(data.select(['title']))\r\n     # ## to int\r\n     # print(data.select(['year']))\r\n-    # ## object from list \r\n+    # # object from list \r\n     # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n \r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n \r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n \r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n+    # print(new_table.select(['cast']))\r\n \r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n+    # # # # FILTRES\r\n     # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n \r\n-    # # #SORT\r\n+    # # # #SORT\r\n     # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n     # # #SORT DESC\r\n     # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n \r\n     # #GROUP BY\r\n     # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n \r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    port = 50052\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedFirstJSON_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    # to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    # object from list \r\n-    ### low level of nulls - first element of list\r\n-    cast_column=data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    first_elements = []\r\n-    for row in cast_list:\r\n-        if row:  # Check if the list is not empty\r\n-            first_elements.append(row[0])\r\n-        else:\r\n-            first_elements.append(None)\r\n-    first_elements_column = pa.array(first_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### medium level of nulls\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 10:\r\n-            tenth_elements.append(row[9])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### high level of nulls - last element of list\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 59:\r\n-            tenth_elements.append(row[58])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-\r\n-    # # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    genres_column = data['genres']\r\n-    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    grouped_table = first_genre_table.group_by('first_genre')\r\n-    print(grouped_table)\r\n-    \r\n-    \r\n-    genres_column = data['genres']\r\n-    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    print(grouped_table)\r\n-\r\n-    cast_column = data['cast']\r\n-    first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    grouped_table = first_cast_table.group_by('first_cast')\r\n-    print(grouped_table)\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n     # genres_column = data['genres']\r\n     # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n     # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n     # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    # print(grouped_table)\r\n     \r\n+    \r\n+    # genres_column = data['genres']\r\n     # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n     # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n     # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n     # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n+    # print(grouped_table)\r\n \r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n     # print(grouped_table)\r\n \r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'JSONPath_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n     # #AGGREGATE FUNCTION\r\n     # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n     \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    port = 50052\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'FlattenedFirstJSON_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    # to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    # object from list \r\n-    ### low level of nulls - first element of list\r\n-    cast_column=data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    first_elements = []\r\n-    for row in cast_list:\r\n-        if row:  # Check if the list is not empty\r\n-            first_elements.append(row[0])\r\n-        else:\r\n-            first_elements.append(None)\r\n-    first_elements_column = pa.array(first_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### medium level of nulls\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 10:\r\n-            tenth_elements.append(row[9])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-    # # ### high level of nulls - last element of list\r\n-    cast_column = data['cast']\r\n-    cast_list = cast_column.to_pylist()\r\n-    tenth_elements = []\r\n-    for row in cast_list:\r\n-        if len(row) >= 59:\r\n-            tenth_elements.append(row[58])\r\n-        else:\r\n-            tenth_elements.append(None)\r\n-    tenth_elements_column = pa.array(tenth_elements)\r\n-    new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    print(new_table.select(['cast']))\r\n-\r\n-    # # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    genres_column = data['genres']\r\n-    first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    grouped_table = first_genre_table.group_by('first_genre')\r\n-    print(grouped_table)\r\n-    \r\n-    \r\n-    genres_column = data['genres']\r\n-    genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    print(grouped_table)\r\n-\r\n-    cast_column = data['cast']\r\n-    first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    grouped_table = first_cast_table.group_by('first_cast')\r\n-    print(grouped_table)\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    \r\n     # genres_column = data['genres']\r\n     # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n     # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n     # grouped_table = first_genre_table.group_by('first_genre')\r\n"
                },
                {
                    "date": 1717950495016,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,401 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    port = 50054\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'SimpleMethod_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+    \r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast_0']))\r\n+    # ### medium level of nulls\r\n+    print(data.select(['cast_9']))\r\n+    # ### high level of nulls - last element of list\r\n+    print(data.select(['cast_58']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres_0'))\r\n+    print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717950631504,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,410 +114,11 @@\n     \r\n     combined_df = pa.concat_tables(combined_df)\r\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n     \r\n     \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n \r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    # port = 50051\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'JSONPath_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast[0]']))\r\n-    # ### medium level of nulls\r\n-    # print(data.select(['cast[9]']))\r\n-    # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast[58]']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres[0]'))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    # print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-    #     print(genre)\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # print(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n     # port = 50052\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'FlattenedFirstJSON_movies'\r\n     # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n"
                },
                {
                    "date": 1717950638887,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,9 +115,9 @@\n     combined_df = pa.concat_tables(combined_df)\r\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n-    \r\n+    #CLOUD PAK\r\n \r\n     # port = 50052\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'FlattenedFirstJSON_movies'\r\n"
                },
                {
                    "date": 1717950740983,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,8 +116,10 @@\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n     #CLOUD PAK\r\n+    \r\n+    co\r\n \r\n     # port = 50052\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'FlattenedFirstJSON_movies'\r\n"
                },
                {
                    "date": 1717951272164,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,405 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    \r\n+    \r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717951279604,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,12 +114,8 @@\n     \r\n     # combined_df = pa.concat_tables(combined_df)\r\n     # combined_df = combined_df.combine_chunks()\r\n     # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    \r\n-    \r\n \r\n     # port = 50052\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'FlattenedFirstJSON_movies'\r\n@@ -401,410 +397,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    port = 50054\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'SimpleMethod_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-    \r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast_0']))\r\n-    # ### medium level of nulls\r\n-    print(data.select(['cast_9']))\r\n-    # ### high level of nulls - last element of list\r\n-    print(data.select(['cast_58']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres_0'))\r\n-    print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    \r\n-    co\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717951286419,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,403 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+        #CLOUD PAK\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717951828216,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,411 +67,11 @@\n     print(combined_df)\r\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n-        #CLOUD PAK\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n+    #CLOUD PAK\r\n     \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n \r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n     # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n"
                },
                {
                    "date": 1717951952616,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,404 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    print()\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717951959476,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,404 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    print(data[])\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717951968932,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n     #CLOUD PAK\r\n-    print(data[])\r\n+    print(data['year'])\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n@@ -400,813 +400,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    print()\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717951998986,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,404 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    print(data['year'].cast)\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952012980,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,404 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    print(data['year'].cast(pa.s))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952075591,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n     #CLOUD PAK\r\n-    print(data['year'].cast(pa.s))\r\n+    print(data.select(['year']).cast(pa.string()))\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n@@ -400,813 +400,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    print(data['year'].cast)\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    print(data['year'])\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952134571,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,404 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    print(data.column('year').cast(pa.string()))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952154607,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n     #CLOUD PAK\r\n-    print(data.column('year').cast(pa.string()))\r\n+    print(data['year'].cast(pa.string))\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n@@ -400,409 +400,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    print(data.select(['year']).cast(pa.string()))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952161449,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n     #CLOUD PAK\r\n-    print(data['year'].cast(pa.string))\r\n+    print(data['year'].cast(pa.s))\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n"
                },
                {
                    "date": 1717952169857,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n     #CLOUD PAK\r\n-    print(data['year'].cast(pa.s))\r\n+    print(data['year'].cast(pa.string))\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n"
                },
                {
                    "date": 1717952176910,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n     #CLOUD PAK\r\n-    print(data['year'].cast(pa.string))\r\n+    # print(data['year'].cast(pa.string()))\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n"
                },
                {
                    "date": 1717952190381,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,405 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([year_column], names=['year']))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952196958,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,405 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952240476,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,406 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    #CLOUD PAK\r\n+    \r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952249205,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,415 +67,11 @@\n     print(combined_df)\r\n     combined_df = combined_df.combine_chunks()\r\n     print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n     \r\n-    #CLOUD PAK\r\n+    ##CLOUD PAK\r\n     \r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n     \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n \r\n     # port = 50054\r\n@@ -807,814 +403,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([year_column], names=['year']))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    #CLOUD PAK\r\n-    # print(data['year'].cast(pa.string()))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952259027,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,407 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    #CONVERT TYPE\r\n+    \r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952318802,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,409 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952326970,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n-    \r\n+    #REMO\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n@@ -405,819 +405,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    #CONVERT TYPE\r\n-    \r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    \r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952437125,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,412 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    \r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952468524,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,412 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    print(table.column_names)\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952475695,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,412 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    print(table.column_names.romove)\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952495261,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,412 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    print(table.column_names.romove('thumbnail_width'))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952511435,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,412 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    print(datadata.column_names.romove('thumbnail_width'))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952518690,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n-    print(datadata.column_names.romove('thumbnail_width'))\r\n+    print(data.select(data.column_names.romove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n     \r\n \r\n@@ -408,2062 +408,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    print(table.column_names.romove('thumbnail_width'))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    print(table.column_names.romove)\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    print(table.column_names)\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    \r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    #REMO\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952529925,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n-    print(data.select(data.column_names.romove('thumbnail_width')))\r\n+    print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n     \r\n \r\n"
                },
                {
                    "date": 1717952551013,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,412 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    print()\r\n+    print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952560437,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,412 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    print(data.column_names)\r\n+    print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952603168,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n     \r\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    print(data.column_names)\r\n+    print(data.column_names.remove('thumbnail_width'))\r\n     print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n     \r\n@@ -408,829 +408,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    print()\r\n-    print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952627510,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     print(data.column_names.remove('thumbnail_width'))\r\n-    print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n     \r\n \r\n"
                },
                {
                    "date": 1717952682306,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,413 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    print(data.column_names.remove('thumbnail_width'))\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952690226,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n     \r\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n+    x=data.column_names\r\n     print(data.column_names.remove('thumbnail_width'))\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n@@ -409,417 +409,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    print(data.column_names.remove('thumbnail_width'))\r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952707047,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,10 +72,10 @@\n     \r\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    x=data.column_names\r\n-    print(data.column_names.remove('thumbnail_width'))\r\n+    x=data.column_names.copy()\r\n+    print(x.remove('thumbnail_width'))\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n     \r\n"
                },
                {
                    "date": 1717952916399,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,414 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    x=data.column_names.copy()\r\n+    print(x)\r\n+    print(x.remove('thumbnail_width'))\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952933302,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,8 +74,9 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     x=data.column_names.copy()\r\n     print(x)\r\n+    y=\r\n     print(x.remove('thumbnail_width'))\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n@@ -410,418 +411,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    x=data.column_names.copy()\r\n-    print(x.remove('thumbnail_width'))\r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717952939377,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,415 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    x=data.column_names.copy()\r\n+    print(x)\r\n+    y=x.remove('thumbnail_width')\r\n+    print(x.remove('thumbnail_width'))\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953044610,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,11 +73,11 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     x=data.column_names.copy()\r\n-    print(x)\r\n+    print(type(x)\r\n     y=x.remove('thumbnail_width')\r\n-    print(x.remove('thumbnail_width'))\r\n+    print(y)\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n     \r\n@@ -411,420 +411,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    x=data.column_names.copy()\r\n-    print(x)\r\n-    y=\r\n-    print(x.remove('thumbnail_width'))\r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953056587,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     x=data.column_names.copy()\r\n-    print(type(x)\r\n+    print(x))\r\n     y=x.remove('thumbnail_width')\r\n     print(y)\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n"
                },
                {
                    "date": 1717953137782,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,10 +73,10 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     x=data.column_names.copy()\r\n-    print(x))\r\n-    y=x.remove('thumbnail_width')\r\n+    print(x)\r\n+    y=x.remove('title')\r\n     print(y)\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n     #REMOVE COLUMN\r\n"
                },
                {
                    "date": 1717953156361,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,415 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    x=data.column_names.copy()\r\n+    print(x)\r\n+    y=x.remove('title')\r\n+    print(data)\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953177057,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n     \r\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    x=data.column_names.copy()\r\n+    x=data.column_names\r\n     print(x)\r\n     y=x.remove('title')\r\n     print(data)\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n@@ -411,420 +411,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    x=data.column_names.copy()\r\n-    print(x)\r\n-    y=x.remove('title')\r\n-    print(y)\r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953184327,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,415 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    x=data.column_names\r\n+    print(x)\r\n+    x.remove('title')\r\n+    print(data)\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953210046,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     x=data.column_names\r\n-    print(x)\r\n+    print(x.remove('title'))\r\n     x.remove('title')\r\n     print(data)\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n     \r\n@@ -411,420 +411,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    x=data.column_names\r\n-    print(x)\r\n-    y=x.remove('title')\r\n-    print(data)\r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953308093,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,414 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    x=data.column_names\r\n+    x.remove('title'))\r\n+    print(data)\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953321974,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,414 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    x=data.column_names\r\n+    print(x.remove(x[0]))\r\n+    print(data)\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953381562,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,8 +72,9 @@\n     \r\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n     x=data.column_names\r\n     print(x.remove(x[0]))\r\n     print(data)\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n@@ -410,834 +411,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    x=data.column_names\r\n-    x.remove('title'))\r\n-    print(data)\r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    x=data.column_names\r\n-    print(x.remove('title'))\r\n-    x.remove('title')\r\n-    print(data)\r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953389121,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,13 +73,8 @@\n     #CONVERT TYPE\r\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n-    x=data.column_names\r\n-    print(x.remove(x[0]))\r\n-    print(data)\r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-    \r\n     #REMOVE COLUMN\r\n     \r\n \r\n     # port = 50054\r\n"
                },
                {
                    "date": 1717953421220,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,11 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n-    \r\n+    x=data.column_names\r\n+    print(x.remove(x[0]))\r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n"
                },
                {
                    "date": 1717953432018,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,10 +74,10 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n-    x=data.column_names\r\n-    print(x.remove(x[0]))\r\n+    # x=data.column_names\r\n+    # print(x.remove(x[0]))\r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n"
                },
                {
                    "date": 1717953440195,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,8 +76,12 @@\n     \r\n     #REMOVE COLUMN\r\n     # x=data.column_names\r\n     # print(x.remove(x[0]))\r\n+    thislist = [\"apple\", \"banana\", \"cherry\"]\r\n+thislist.remove(\"banana\")\r\n+print(thislist)\r\n+    \r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n"
                },
                {
                    "date": 1717953462713,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,10 +77,10 @@\n     #REMOVE COLUMN\r\n     # x=data.column_names\r\n     # print(x.remove(x[0]))\r\n     thislist = [\"apple\", \"banana\", \"cherry\"]\r\n-thislist.remove(\"banana\")\r\n-print(thislist)\r\n+    thislist.remove(thislist)\r\n+    print(thislist)\r\n     \r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n \r\n     # port = 50054\r\n"
                },
                {
                    "date": 1717953475991,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,11 +76,11 @@\n     \r\n     #REMOVE COLUMN\r\n     # x=data.column_names\r\n     # print(x.remove(x[0]))\r\n-    thislist = [\"apple\", \"banana\", \"cherry\"]\r\n-    thislist.remove(thislist)\r\n-    print(thislist)\r\n+    # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n+    # thislist.remove(thislist[0])\r\n+    # print(thislist)\r\n     \r\n     # print(data.select(data.column_names.remove('thumbnail_width')))\r\n \r\n     # port = 50054\r\n"
                },
                {
                    "date": 1717953485296,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,10 +74,11 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n-    # x=data.column_names\r\n+    x=data.column_names.copy()\r\n     # print(x.remove(x[0]))\r\n+    \r\n     # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n     # thislist.remove(thislist[0])\r\n     # print(thislist)\r\n     \r\n"
                },
                {
                    "date": 1717953521201,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,417 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    x=data.column_names\r\n+    print(x.remove(x[0]))\r\n+    \r\n+    # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n+    # thislist.remove(thislist[0])\r\n+    # print(thislist)\r\n+    \r\n+    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953729117,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n-    x=data.column_names\r\n+    x=data.column_names.copy()\r\n     print(x.remove(x[0]))\r\n     \r\n     # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n     # thislist.remove(thislist[0])\r\n@@ -413,422 +413,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    x=data.column_names.copy()\r\n-    # print(x.remove(x[0]))\r\n-    \r\n-    # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n-    # thislist.remove(thislist[0])\r\n-    # print(thislist)\r\n-    \r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953771825,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n-    x=data.column_names.copy()\r\n+    =data.column_names.copy()\r\n     print(x.remove(x[0]))\r\n     \r\n     # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n     # thislist.remove(thislist[0])\r\n"
                },
                {
                    "date": 1717953778265,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n-    =data.column_names.copy()\r\n+    column_names =data.column_names.copy()\r\n     print(x.remove(x[0]))\r\n     \r\n     # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n     # thislist.remove(thislist[0])\r\n"
                },
                {
                    "date": 1717953785899,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,9 +75,9 @@\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n     column_names =data.column_names.copy()\r\n-    print(x.remove(x[0]))\r\n+    print(column_names.remove(column_names[0]))\r\n     \r\n     # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n     # thislist.remove(thislist[0])\r\n     # print(thislist)\r\n"
                },
                {
                    "date": 1717953835687,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,11 +74,13 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n-    column_names =data.column_names.copy()\r\n+    column_names = data.column_names.copy()\r\n     print(column_names.remove(column_names[0]))\r\n     \r\n+    print(data.select(column_names))\r\n+    \r\n     # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n     # thislist.remove(thislist[0])\r\n     # print(thislist)\r\n     \r\n"
                },
                {
                    "date": 1717953878452,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,9 +75,9 @@\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n-    print(column_names.remove(column_names[0]))\r\n+    column_names.remove(column_names[0]))\r\n     \r\n     print(data.select(column_names))\r\n     \r\n     # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n"
                },
                {
                    "date": 1717953912435,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,414 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    column_names = data.column_names.copy()\r\n+    column_names.remove(column_names[0])\r\n+    print(data.select(column_names))\r\n+    \r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953924050,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,414 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    #REMOVE COLUMN\r\n+    column_names = data.column_names.copy()\r\n+    column_names.remove(column_names[0])\r\n+    print(data.select(column_names))\r\n+    \r\n+    #REPLACE\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953932235,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,9 +78,9 @@\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n     \r\n-    #REPLACE\r\n+    #REPLACE MISSING VALUES\r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n@@ -410,838 +410,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    column_names = data.column_names.copy()\r\n-    column_names.remove(column_names[0])\r\n-    print(data.select(column_names))\r\n-    \r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    column_names = data.column_names.copy()\r\n-    column_names.remove(column_names[0]))\r\n-    \r\n-    print(data.select(column_names))\r\n-    \r\n-    # thislist = [\"apple\", \"banana\", \"cherry\"]\r\n-    # thislist.remove(thislist[0])\r\n-    # print(thislist)\r\n-    \r\n-    # print(data.select(data.column_names.remove('thumbnail_width')))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953964309,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,8 +79,10 @@\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n     \r\n     #REPLACE MISSING VALUES\r\n+    \r\n+    \r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n"
                },
                {
                    "date": 1717953971141,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,415 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    \r\n+    #REPLACE MISSING VALUES\r\n+    \r\n+    #REMOVE COLUMN\r\n+    column_names = data.column_names.copy()\r\n+    column_names.remove(column_names[0])\r\n+    print(data.select(column_names))\r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717953977498,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,429 +76,19 @@\n     \r\n     \r\n     #REPLACE MISSING VALUES\r\n     \r\n+    \r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n     \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n     \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n     \r\n     \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n     \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n \r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    #REMOVE COLUMN\r\n-    column_names = data.column_names.copy()\r\n-    column_names.remove(column_names[0])\r\n-    print(data.select(column_names))\r\n-    \r\n-    #REPLACE MISSING VALUES\r\n-    \r\n-    \r\n-\r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n     # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n"
                },
                {
                    "date": 1717953987404,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,9 +76,9 @@\n     \r\n     \r\n     #REPLACE MISSING VALUES\r\n     \r\n-    \r\n+    #CONCATENATE \r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n"
                },
                {
                    "date": 1717953994455,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,9 +76,11 @@\n     \r\n     \r\n     #REPLACE MISSING VALUES\r\n     \r\n-    #CONCATENATE \r\n+    #CONCATENATE COLUMNS\r\n+    \r\n+    #\r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n"
                },
                {
                    "date": 1717954001329,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,9 +78,11 @@\n     #REPLACE MISSING VALUES\r\n     \r\n     #CONCATENATE COLUMNS\r\n     \r\n-    #\r\n+    #SELF JOIN\r\n+    \r\n+    \r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n"
                },
                {
                    "date": 1717954002523,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,9 +80,9 @@\n     #CONCATENATE COLUMNS\r\n     \r\n     #SELF JOIN\r\n     \r\n-    \r\n+    #\r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n"
                },
                {
                    "date": 1717954009778,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,426 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    \r\n+    #REPLACE MISSING VALUES\r\n+    \r\n+    #CONCATENATE COLUMNS\r\n+    \r\n+    #SELF JOIN\r\n+    \r\n+    #SPLIT COLUMN\r\n+    \r\n+    #REMOVE COLUMN\r\n+    column_names = data.column_names.copy()\r\n+    column_names.remove(column_names[0])\r\n+    print(data.select(column_names))\r\n+    \r\n+    \r\n+    \r\n+    \r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717954016812,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,427 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    \r\n+    #REPLACE MISSING VALUES\r\n+    \r\n+    #CONCATENATE COLUMNS\r\n+    \r\n+    #SELF JOIN\r\n+    \r\n+    #SPLIT COLUMN\r\n+    \r\n+    \r\n+    #REMOVE COLUMN\r\n+    column_names = data.column_names.copy()\r\n+    column_names.remove(column_names[0])\r\n+    print(data.select(column_names))\r\n+    \r\n+    \r\n+    \r\n+    \r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717954025065,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -82,435 +82,11 @@\n     #SELF JOIN\r\n     \r\n     #SPLIT COLUMN\r\n     \r\n+    #UNION TABLES\r\n     \r\n-    #REMOVE COLUMN\r\n-    column_names = data.column_names.copy()\r\n-    column_names.remove(column_names[0])\r\n-    print(data.select(column_names))\r\n     \r\n-    \r\n-    \r\n-    \r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    \r\n-    #REPLACE MISSING VALUES\r\n-    \r\n-    #CONCATENATE COLUMNS\r\n-    \r\n-    #SELF JOIN\r\n-    \r\n-    #SPLIT COLUMN\r\n-    \r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n@@ -849,430 +425,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    \r\n-    #REPLACE MISSING VALUES\r\n-    \r\n-    #CONCATENATE COLUMNS\r\n-    \r\n-    #SELF JOIN\r\n-    \r\n-    #\r\n-    #REMOVE COLUMN\r\n-    column_names = data.column_names.copy()\r\n-    column_names.remove(column_names[0])\r\n-    print(data.select(column_names))\r\n-    \r\n-    \r\n-    \r\n-    \r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717954026354,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,9 +84,9 @@\n     #SPLIT COLUMN\r\n     \r\n     #UNION TABLES\r\n     \r\n-    \r\n+    #S\r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n"
                },
                {
                    "date": 1717954032809,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,9 +84,10 @@\n     #SPLIT COLUMN\r\n     \r\n     #UNION TABLES\r\n     \r\n-    #S\r\n+    #SAMPLE TABLE\r\n+    \r\n     #REMOVE COLUMN\r\n     column_names = data.column_names.copy()\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n"
                },
                {
                    "date": 1717957804764,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -87,9 +87,9 @@\n     \r\n     #SAMPLE TABLE\r\n     \r\n     #REMOVE COLUMN\r\n-    column_names = data.column_names.copy()\r\n+    column_names = data.column_names\r\n     column_names.remove(column_names[0])\r\n     print(data.select(column_names))\r\n     \r\n     \r\n"
                },
                {
                    "date": 1717957833287,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -88,9 +88,9 @@\n     #SAMPLE TABLE\r\n     \r\n     #REMOVE COLUMN\r\n     column_names = data.column_names\r\n-    column_names.remove(column_names[0])\r\n+    column_names.remove('title')\r\n     print(data.select(column_names))\r\n     \r\n     \r\n     \r\n"
                },
                {
                    "date": 1717957853577,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -93,10 +93,8 @@\n     print(data.select(column_names))\r\n     \r\n     \r\n     \r\n-    \r\n-    \r\n \r\n     # port = 50054\r\n     # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n     # table_name = 'SimpleMethod_movies'\r\n"
                },
                {
                    "date": 1717957928681,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,12 +74,12 @@\n     # print(data['year'].cast(pa.string()))\r\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     \r\n-    #REPLACE MISSING VALUES\r\n     \r\n-    #CONCATENATE COLUMNS\r\n     \r\n+    #CONCATENATE COLUMNS#REPLACE MISSING VALUES\r\n+    \r\n     #SELF JOIN\r\n     \r\n     #SPLIT COLUMN\r\n     \r\n"
                },
                {
                    "date": 1717957937188,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,9 +76,10 @@\n     \r\n     \r\n     \r\n     \r\n-    #CONCATENATE COLUMNS#REPLACE MISSING VALUES\r\n+    #CONCATENATE COLUMNS\r\n+    #REPLACE MISSING VALUES\r\n     \r\n     #SELF JOIN\r\n     \r\n     #SPLIT COLUMN\r\n"
                },
                {
                    "date": 1717957944933,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,427 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    #CONCATENATE COLUMNS\r\n+    \r\n+    #REPLACE MISSING VALUES\r\n+    \r\n+    #SELF JOIN\r\n+    \r\n+    #SPLIT COLUMN\r\n+    \r\n+    #UNION TABLES\r\n+    \r\n+    #SAMPLE TABLE\r\n+    \r\n+    #REMOVE COLUMN\r\n+    column_names = data.column_names\r\n+    column_names.remove('title')\r\n+    print(data.select(column_names))\r\n+    \r\n+    \r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717957953359,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,10 +79,8 @@\n     #REPLACE MISSING VALUES\r\n     \r\n     #SELF JOIN\r\n     \r\n-    #SPLIT COLUMN\r\n-    \r\n     #UNION TABLES\r\n     \r\n     #SAMPLE TABLE\r\n     \r\n@@ -423,434 +421,5 @@\n     # print(grouped)\r\n \r\n if __name__ == '__main__':\r\n     client_reddit()\r\n-    # client_example()\n-import pyarrow.flight as flight\r\n-import pyarrow.compute as pc\r\n-import pyarrow as pa\r\n-import pandas as pd\r\n-\r\n-def client_example():\r\n-    ports = [50051, 50052, 50053, 50054]\r\n-    for port in ports:\r\n-        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n-        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n-\r\n-        for table_name in table_names:\r\n-            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-            data = reader.read_all()\r\n-            print(f\"Data from table {port}:: '{table_name}':\")\r\n-            # print(data)\r\n-#Movies\r\n-def client_reddit():\r\n-    port = 50051\r\n-    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    table_name = 'JSONPath_movies'\r\n-    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    data = reader.read_all()\r\n-\r\n-    # SELECTION\r\n-    # first level query\r\n-    ## to string\r\n-    print(data.select(['title']))\r\n-    ## to int\r\n-    print(data.select(['year']))\r\n-    ## object from list \r\n-    ### low level of nulls - first element of list\r\n-    print(data.select(['cast[0]']))\r\n-    ### medium level of nulls\r\n-    print(data.select(['cast[9]']))\r\n-    ### high level of nulls - last element of list\r\n-    print(data.select(['cast[58]']))\r\n-\r\n-    # # FILTRES\r\n-    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # #SORT\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # #SORT DESC\r\n-    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    #GROUP BY\r\n-    print(pa.TableGroupBy(data,'year'))\r\n-    print(pa.TableGroupBy(data,'genres[0]'))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n-    print(pa.TableGroupBy(data,'cast[0]'))\r\n-\r\n-    #AGGREGATE FUNCTION\r\n-    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n-    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n-\r\n-\r\n-    combined_df = []\r\n-    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n-        print(genre)\r\n-        df_genre = data.select([genre]).rename_columns(['genre'])\r\n-        combined_df.append(df_genre)\r\n-    \r\n-    combined_df = pa.concat_tables(combined_df)\r\n-    print(combined_df)\r\n-    combined_df = combined_df.combine_chunks()\r\n-    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-    \r\n-    ##CLOUD PAK\r\n-    \r\n-    #CONVERT TYPE\r\n-    # print(data['year'].cast(pa.string()))\r\n-    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n-    \r\n-    \r\n-    \r\n-    \r\n-    #CONCATENATE COLUMNS\r\n-    #REPLACE MISSING VALUES\r\n-    \r\n-    #SELF JOIN\r\n-    \r\n-    #SPLIT COLUMN\r\n-    \r\n-    #UNION TABLES\r\n-    \r\n-    #SAMPLE TABLE\r\n-    \r\n-    #REMOVE COLUMN\r\n-    column_names = data.column_names\r\n-    column_names.remove('title')\r\n-    print(data.select(column_names))\r\n-    \r\n-    \r\n-    \r\n-\r\n-    # port = 50054\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'SimpleMethod_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # ## to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # ## object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # print(data.select(['cast_0']))\r\n-    # # ### medium level of nulls\r\n-    # print(data.select(['cast_9']))\r\n-    # # ### high level of nulls - last element of list\r\n-    # print(data.select(['cast_58']))\r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-    # print(pa.TableGroupBy(data,'genres_0'))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n-    # print(pa.TableGroupBy(data,'cast_0'))\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n-    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-\r\n-    # combined_df = []\r\n-    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n-    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n-    #     combined_df.append(df_genre)\r\n-    \r\n-    # combined_df = pa.concat_tables(combined_df)\r\n-    # combined_df = combined_df.combine_chunks()\r\n-    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n-\r\n-    # port = 50052\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # table_name = 'FlattenedFirstJSON_movies'\r\n-    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n-    # data = reader.read_all()\r\n-\r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(data.select(['title']))\r\n-    # ## to int\r\n-    # print(data.select(['year']))\r\n-    # # object from list \r\n-    # ### low level of nulls - first element of list\r\n-    # cast_column=data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # first_elements = []\r\n-    # for row in cast_list:\r\n-    #     if row:  # Check if the list is not empty\r\n-    #         first_elements.append(row[0])\r\n-    #     else:\r\n-    #         first_elements.append(None)\r\n-    # first_elements_column = pa.array(first_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### medium level of nulls\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 10:\r\n-    #         tenth_elements.append(row[9])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-    # # # ### high level of nulls - last element of list\r\n-    # cast_column = data['cast']\r\n-    # cast_list = cast_column.to_pylist()\r\n-    # tenth_elements = []\r\n-    # for row in cast_list:\r\n-    #     if len(row) >= 59:\r\n-    #         tenth_elements.append(row[58])\r\n-    #     else:\r\n-    #         tenth_elements.append(None)\r\n-    # tenth_elements_column = pa.array(tenth_elements)\r\n-    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n-\r\n-    # print(new_table.select(['cast']))\r\n-\r\n-    # # # # FILTRES\r\n-    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n-\r\n-    # # # #SORT\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # #GROUP BY\r\n-    # print(pa.TableGroupBy(data,'year'))\r\n-\r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table)\r\n-    \r\n-    \r\n-    # genres_column = data['genres']\r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_column = data['cast']\r\n-    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n-    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n-    # grouped_table = first_cast_table.group_by('first_cast')\r\n-    # print(grouped_table)\r\n-\r\n-    # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_column = data['genres']\r\n-    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n-    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n-    # grouped_table = first_genre_table.group_by('first_genre')\r\n-    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n-    \r\n-    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n-    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n-    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n-    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n-    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n-    \r\n-    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-    \r\n-    # port = 50053\r\n-    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n-    # main_table_name = 'TablesMethod_movies'\r\n-    # cast_table_name = 'TablesMethod_movies_cast'\r\n-    # genres_table_name = 'TablesMethod_movies_genres'\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n-    # main_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n-    # cast_data = reader.read_all()\r\n-    \r\n-    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n-    # genres_data = reader.read_all()\r\n-    \r\n-    # # SELECTION\r\n-    # # first level query\r\n-    # # to string\r\n-    # print(main_data.select(['title']))\r\n-    # ## to int\r\n-    # print(main_data.select(['year']))\r\n-    # # ## object from list \r\n-    # # ### low level of nulls - first element of list\r\n-    # print(cast_data)\r\n-    \r\n-    # grouped_table = cast_data.group_by('row_number')\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-\r\n-    # # ### medium level of nulls\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-    # # ### high level of nulls - last element of list\r\n-    # # print(data.select(['cast[58]']))\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n-    # tenth_values_array  = pa.array(tenth_values )\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n-    # print(result_table)\r\n-    \r\n-\r\n-    # # # FILTRES\r\n-    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n-\r\n-    # # #SORT\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n-    # # #SORT DESC\r\n-    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n-\r\n-    # # #GROUP BY\r\n-    # print(pa.TableGroupBy(main_data,'year'))\r\n-\r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table)\r\n-\r\n-    # cast_row_number=cast_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value'))\r\n-\r\n-    # # #AGGREGATE FUNCTION\r\n-    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n-    \r\n-    # genres_row_number=genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n-    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n-    \r\n-    # genres_row_number = genres_data['row_number']\r\n-    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n-    # aggregated_values = {}\r\n-    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n-    #     if row_number not in aggregated_values:\r\n-    #         aggregated_values[row_number] = value_list\r\n-    #     else:\r\n-    #         aggregated_values[row_number].extend(value_list)\r\n-    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n-    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n-    # first_values_array = pa.array(first_values)\r\n-    # second_values_array = pa.array(second_values)\r\n-    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n-    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n-    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n-\r\n-\r\n-    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n-    # grouped_data = {'row_number': [], 'value': []}\r\n-    # for row_num in unique_row_numbers:\r\n-    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n-    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n-    #     grouped_data['row_number'].append(row_num.as_py())\r\n-    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n-    # grouped_table = pa.table(grouped_data)\r\n-    \r\n-    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n-    # data_with_strings = pa.table({'genres': genres_as_string})\r\n-    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n-    # print(grouped)\r\n-\r\n-if __name__ == '__main__':\r\n-    client_reddit()\r\n     # client_example()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717957960124,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,8 +75,10 @@\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #CONCATENATE COLUMNS\r\n     \r\n+    #SPLIT COLUMN\r\n+    \r\n     #REPLACE MISSING VALUES\r\n     \r\n     #SELF JOIN\r\n     \r\n"
                },
                {
                    "date": 1717958374154,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,8 +75,9 @@\n     print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n     \r\n     #CONCATENATE COLUMNS\r\n     columns = [table[column].cast('string') for column in columns_to_concat]\r\n+    \r\n     #SPLIT COLUMN\r\n     \r\n     #REPLACE MISSING VALUES\r\n     \r\n"
                },
                {
                    "date": 1717958443783,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,430 @@\n+import pyarrow.flight as flight\r\n+import pyarrow.compute as pc\r\n+import pyarrow as pa\r\n+import pandas as pd\r\n+\r\n+def client_example():\r\n+    ports = [50051, 50052, 50053, 50054]\r\n+    for port in ports:\r\n+        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n+        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n+\r\n+        for table_name in table_names:\r\n+            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+            data = reader.read_all()\r\n+            print(f\"Data from table {port}:: '{table_name}':\")\r\n+            # print(data)\r\n+#Movies\r\n+def client_reddit():\r\n+    port = 50051\r\n+    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    table_name = 'JSONPath_movies'\r\n+    reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    data = reader.read_all()\r\n+\r\n+    # SELECTION\r\n+    # first level query\r\n+    ## to string\r\n+    print(data.select(['title']))\r\n+    ## to int\r\n+    print(data.select(['year']))\r\n+    ## object from list \r\n+    ### low level of nulls - first element of list\r\n+    print(data.select(['cast[0]']))\r\n+    ### medium level of nulls\r\n+    print(data.select(['cast[9]']))\r\n+    ### high level of nulls - last element of list\r\n+    print(data.select(['cast[58]']))\r\n+\r\n+    # # FILTRES\r\n+    print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # #SORT\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # #SORT DESC\r\n+    print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    #GROUP BY\r\n+    print(pa.TableGroupBy(data,'year'))\r\n+    print(pa.TableGroupBy(data,'genres[0]'))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n+    print(pa.TableGroupBy(data,'cast[0]'))\r\n+\r\n+    #AGGREGATE FUNCTION\r\n+    print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n+    print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n+\r\n+\r\n+    combined_df = []\r\n+    for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n+        print(genre)\r\n+        df_genre = data.select([genre]).rename_columns(['genre'])\r\n+        combined_df.append(df_genre)\r\n+    \r\n+    combined_df = pa.concat_tables(combined_df)\r\n+    print(combined_df)\r\n+    combined_df = combined_df.combine_chunks()\r\n+    print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+    \r\n+    ##CLOUD PAK\r\n+    \r\n+    #CONVERT TYPE\r\n+    # print(data['year'].cast(pa.string()))\r\n+    print(pa.Table.from_arrays([data.column('year').cast(pa.string())], names=['year']))\r\n+    \r\n+    #CONCATENATE COLUMNS\r\n+    columns = [data[column].cast('string') for column in ['title','year']]\r\n+    concatenated = pc.binary_join_element_wise(*columns, separator=pa.scalar('-'))\r\n+    concatenated = concatenated.fill_null('')\r\n+    \r\n+    #SPLIT COLUMN\r\n+    \r\n+    #REPLACE MISSING VALUES\r\n+    \r\n+    #SELF JOIN\r\n+    \r\n+    #UNION TABLES\r\n+    \r\n+    #SAMPLE TABLE\r\n+    \r\n+    #REMOVE COLUMN\r\n+    column_names = data.column_names\r\n+    column_names.remove('title')\r\n+    print(data.select(column_names))\r\n+    \r\n+    \r\n+    \r\n+\r\n+    # port = 50054\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'SimpleMethod_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # ## to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # ## object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # print(data.select(['cast_0']))\r\n+    # # ### medium level of nulls\r\n+    # print(data.select(['cast_9']))\r\n+    # # ### high level of nulls - last element of list\r\n+    # print(data.select(['cast_58']))\r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+    # print(pa.TableGroupBy(data,'genres_0'))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n+    # print(pa.TableGroupBy(data,'cast_0'))\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n+    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+\r\n+    # combined_df = []\r\n+    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n+    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n+    #     combined_df.append(df_genre)\r\n+    \r\n+    # combined_df = pa.concat_tables(combined_df)\r\n+    # combined_df = combined_df.combine_chunks()\r\n+    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n+\r\n+    # port = 50052\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # table_name = 'FlattenedFirstJSON_movies'\r\n+    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n+    # data = reader.read_all()\r\n+\r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(data.select(['title']))\r\n+    # ## to int\r\n+    # print(data.select(['year']))\r\n+    # # object from list \r\n+    # ### low level of nulls - first element of list\r\n+    # cast_column=data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # first_elements = []\r\n+    # for row in cast_list:\r\n+    #     if row:  # Check if the list is not empty\r\n+    #         first_elements.append(row[0])\r\n+    #     else:\r\n+    #         first_elements.append(None)\r\n+    # first_elements_column = pa.array(first_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### medium level of nulls\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 10:\r\n+    #         tenth_elements.append(row[9])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+    # # # ### high level of nulls - last element of list\r\n+    # cast_column = data['cast']\r\n+    # cast_list = cast_column.to_pylist()\r\n+    # tenth_elements = []\r\n+    # for row in cast_list:\r\n+    #     if len(row) >= 59:\r\n+    #         tenth_elements.append(row[58])\r\n+    #     else:\r\n+    #         tenth_elements.append(None)\r\n+    # tenth_elements_column = pa.array(tenth_elements)\r\n+    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n+\r\n+    # print(new_table.select(['cast']))\r\n+\r\n+    # # # # FILTRES\r\n+    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n+\r\n+    # # # #SORT\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # #GROUP BY\r\n+    # print(pa.TableGroupBy(data,'year'))\r\n+\r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table)\r\n+    \r\n+    \r\n+    # genres_column = data['genres']\r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_column = data['cast']\r\n+    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n+    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n+    # grouped_table = first_cast_table.group_by('first_cast')\r\n+    # print(grouped_table)\r\n+\r\n+    # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_column = data['genres']\r\n+    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n+    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n+    # grouped_table = first_genre_table.group_by('first_genre')\r\n+    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n+    \r\n+    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n+    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n+    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n+    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n+    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n+    \r\n+    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+    \r\n+    # port = 50053\r\n+    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n+    # main_table_name = 'TablesMethod_movies'\r\n+    # cast_table_name = 'TablesMethod_movies_cast'\r\n+    # genres_table_name = 'TablesMethod_movies_genres'\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n+    # main_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n+    # cast_data = reader.read_all()\r\n+    \r\n+    # reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n+    # genres_data = reader.read_all()\r\n+    \r\n+    # # SELECTION\r\n+    # # first level query\r\n+    # # to string\r\n+    # print(main_data.select(['title']))\r\n+    # ## to int\r\n+    # print(main_data.select(['year']))\r\n+    # # ## object from list \r\n+    # # ### low level of nulls - first element of list\r\n+    # print(cast_data)\r\n+    \r\n+    # grouped_table = cast_data.group_by('row_number')\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+\r\n+    # # ### medium level of nulls\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+    # # ### high level of nulls - last element of list\r\n+    # # print(data.select(['cast[58]']))\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n+    # tenth_values_array  = pa.array(tenth_values )\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n+    # print(result_table)\r\n+    \r\n+\r\n+    # # # FILTRES\r\n+    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n+\r\n+    # # #SORT\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n+    # # #SORT DESC\r\n+    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n+\r\n+    # # #GROUP BY\r\n+    # print(pa.TableGroupBy(main_data,'year'))\r\n+\r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table)\r\n+\r\n+    # cast_row_number=cast_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value'))\r\n+\r\n+    # # #AGGREGATE FUNCTION\r\n+    # print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n+    \r\n+    # genres_row_number=genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n+    # print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n+    \r\n+    # genres_row_number = genres_data['row_number']\r\n+    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n+    # aggregated_values = {}\r\n+    # for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n+    #     if row_number not in aggregated_values:\r\n+    #         aggregated_values[row_number] = value_list\r\n+    #     else:\r\n+    #         aggregated_values[row_number].extend(value_list)\r\n+    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n+    # second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n+    # first_values_array = pa.array(first_values)\r\n+    # second_values_array = pa.array(second_values)\r\n+    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n+    # grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n+    # print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n+\r\n+\r\n+    # unique_row_numbers = pc.unique(genres_data['row_number'])\r\n+    # grouped_data = {'row_number': [], 'value': []}\r\n+    # for row_num in unique_row_numbers:\r\n+    #     mask = pc.equal(genres_data['row_number'], row_num)\r\n+    #     filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n+    #     grouped_data['row_number'].append(row_num.as_py())\r\n+    #     grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n+    # grouped_table = pa.table(grouped_data)\r\n+    \r\n+    # genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n+    # data_with_strings = pa.table({'genres': genres_as_string})\r\n+    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n+    # print(grouped)\r\n+\r\n+if __name__ == '__main__':\r\n+    client_reddit()\r\n+    # client_example()\n\\ No newline at end of file\n"
                }
            ],
            "date": 1717946305598,
            "name": "Commit-0",
            "content": "import pyarrow.flight as flight\r\nimport pyarrow.compute as pc\r\nimport pyarrow as pa\r\nimport pandas as pd\r\n\r\ndef client_example():\r\n    ports = [50051, 50052, 50053, 50054]\r\n    for port in ports:\r\n        client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n        reader = client.do_get(flight.Ticket(\"get_table_names\".encode())) \r\n        table_names = reader.read_all().to_pandas()[\"table_name\"].tolist()\r\n\r\n        for table_name in table_names:\r\n            reader = client.do_get(flight.Ticket(table_name.encode()))\r\n            data = reader.read_all()\r\n            print(f\"Data from table {port}:: '{table_name}':\")\r\n            # print(data)\r\n#Movies\r\ndef client_reddit():\r\n    # port = 50051\r\n    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n\r\n    # table_name = 'FlattenedJSON_movies'\r\n    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n    # data = reader.read_all()\r\n\r\n    # # SELECTION\r\n    # # first level query\r\n    # ## to string\r\n    # print(data.select(['title']))\r\n    # ## to int\r\n    # print(data.select(['year']))\r\n    # ## object from list \r\n    # ### low level of nulls - first element of list\r\n    # print(data.select(['cast[0]']))\r\n    # ### medium level of nulls\r\n    # print(data.select(['cast[9]']))\r\n    # ### high level of nulls - last element of list\r\n    # print(data.select(['cast[58]']))\r\n\r\n    # # # FILTRES\r\n    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n\r\n    # # #SORT\r\n    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n    # # #SORT DESC\r\n    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n\r\n    # #GROUP BY\r\n    # print(pa.TableGroupBy(data,'year'))\r\n    # print(pa.TableGroupBy(data,'genres[0]'))\r\n    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']))\r\n    # print(pa.TableGroupBy(data,'cast[0]'))\r\n\r\n    # #AGGREGATE FUNCTION\r\n    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n    # print(pa.TableGroupBy(data, 'genres[0]').aggregate([('genres[0]', \"count\")]))\r\n    # print(pa.TableGroupBy(data, ['genres[0]','genres[1]']).aggregate([('genres[0]', \"count\"),('genres[1]', \"count\")]))\r\n\r\n\r\n    # combined_df = []\r\n    # for genre in filter(lambda x: ('genre' in x), data.schema.names):\r\n    #     print(genre)\r\n    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n    #     combined_df.append(df_genre)\r\n    \r\n    # combined_df = pa.concat_tables(combined_df)\r\n    # print(combined_df)\r\n    # combined_df = combined_df.combine_chunks()\r\n    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n\r\n    # port = 50054\r\n    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n    # table_name = 'SimpleMethod_movies'\r\n    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n    # data = reader.read_all()\r\n    \r\n    # # SELECTION\r\n    # # first level query\r\n    # ## to string\r\n    # print(data.select(['title']))\r\n    # ## to int\r\n    # print(data.select(['year']))\r\n    # ## object from list \r\n    # ### low level of nulls - first element of list\r\n    # print(data.select(['cast_0']))\r\n    # # ### medium level of nulls\r\n    # print(data.select(['cast_9']))\r\n    # # ### high level of nulls - last element of list\r\n    # print(data.select(['cast_58']))\r\n\r\n    # # # FILTRES\r\n    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n\r\n    # # #SORT\r\n    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n    # # #SORT DESC\r\n    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n\r\n    # #GROUP BY\r\n    # print(pa.TableGroupBy(data,'year'))\r\n    # print(pa.TableGroupBy(data,'genres_0'))\r\n    # print(pa.TableGroupBy(data, ['genres_0','genres_1']))\r\n    # print(pa.TableGroupBy(data,'cast_0'))\r\n\r\n    # #AGGREGATE FUNCTION\r\n    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n    # print(pa.TableGroupBy(data, ['genres_0','genres_1']).aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n\r\n    # combined_df = []\r\n    # for genre in filter(lambda x: ('genres_' in x), data.schema.names):\r\n    #     df_genre = data.select([genre]).rename_columns(['genre'])\r\n    #     combined_df.append(df_genre)\r\n    \r\n    # combined_df = pa.concat_tables(combined_df)\r\n    # combined_df = combined_df.combine_chunks()\r\n    # print(pa.TableGroupBy(combined_df, ['genre']).aggregate([('genre', \"count\")]))\r\n\r\n    # port = 50052\r\n    # client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n    # table_name = 'FlattenedJSON_movies'\r\n    # reader = client.do_get(flight.Ticket(table_name.encode()))\r\n    # data = reader.read_all()\r\n\r\n    # SELECTION\r\n    # first level query\r\n    ## to string\r\n    # print(data.select(['title']))\r\n    # ## to int\r\n    # print(data.select(['year']))\r\n    # # object from list \r\n    # ### low level of nulls - first element of list\r\n    # cast_column=data['cast']\r\n    # cast_list = cast_column.to_pylist()\r\n    # first_elements = []\r\n    # for row in cast_list:\r\n    #     if row:  # Check if the list is not empty\r\n    #         first_elements.append(row[0])\r\n    #     else:\r\n    #         first_elements.append(None)\r\n    # first_elements_column = pa.array(first_elements)\r\n    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', first_elements_column)\r\n\r\n    # print(new_table.select(['cast']))\r\n    # # # ### medium level of nulls\r\n    # cast_column = data['cast']\r\n    # cast_list = cast_column.to_pylist()\r\n    # tenth_elements = []\r\n    # for row in cast_list:\r\n    #     if len(row) >= 10:\r\n    #         tenth_elements.append(row[9])\r\n    #     else:\r\n    #         tenth_elements.append(None)\r\n    # tenth_elements_column = pa.array(tenth_elements)\r\n    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n\r\n    # print(new_table.select(['cast']))\r\n    # # # ### high level of nulls - last element of list\r\n    # cast_column = data['cast']\r\n    # cast_list = cast_column.to_pylist()\r\n    # tenth_elements = []\r\n    # for row in cast_list:\r\n    #     if len(row) >= 59:\r\n    #         tenth_elements.append(row[58])\r\n    #     else:\r\n    #         tenth_elements.append(None)\r\n    # tenth_elements_column = pa.array(tenth_elements)\r\n    # new_table = data.set_column(data.schema.get_field_index('cast'), 'cast', tenth_elements_column)\r\n\r\n    # print(new_table.select(['cast']))\r\n\r\n    # # # # FILTRES\r\n    # print(pc.filter(data, pc.greater(data.column('year'), 2000)))\r\n\r\n    # # # #SORT\r\n    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"ascending\")])))\r\n    # # #SORT DESC\r\n    # print(pc.take(data,pc.sort_indices(data, sort_keys=[(\"title\", \"descending\")])))\r\n\r\n    # #GROUP BY\r\n    # print(pa.TableGroupBy(data,'year'))\r\n\r\n    # genres_column = data['genres']\r\n    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n    # grouped_table = first_genre_table.group_by('first_genre')\r\n    # print(grouped_table)\r\n    \r\n    \r\n    # genres_column = data['genres']\r\n    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n    # print(grouped_table)\r\n\r\n    # cast_column = data['cast']\r\n    # first_cast  = [str(row[0]) if row else None for row in cast_column]\r\n    # first_cast_table = pa.Table.from_arrays([first_cast], names=['first_cast'])\r\n    # grouped_table = first_cast_table.group_by('first_cast')\r\n    # print(grouped_table)\r\n\r\n    # #AGGREGATE FUNCTION\r\n    # print(pa.TableGroupBy(data,'year').aggregate([(\"year\", \"count\")]))\r\n    # print(pa.TableGroupBy(data, 'genres_0').aggregate([('genres_0', \"count\")]))\r\n    \r\n    # genres_column = data['genres']\r\n    # first_genres  = [str(row[0]) if row else None for row in genres_column]\r\n    # first_genre_table = pa.Table.from_arrays([first_genres], names=['first_genre'])\r\n    # grouped_table = first_genre_table.group_by('first_genre')\r\n    # print(grouped_table.aggregate([('first_genre', 'count')]))\r\n    \r\n    # genres_0 = [str(row[0]) if row else None for row in genres_column]\r\n    # genres_1 = [str(row[1]) if len(row) > 1 else None for row in genres_column]\r\n    # group_table = pa.Table.from_arrays([genres_0, genres_1], names=['genres_0', 'genres_1'])\r\n    # grouped_table = group_table.group_by(['genres_0', 'genres_1'])\r\n    # print(grouped_table.aggregate([('genres_0', \"count\"),('genres_1', \"count\")]))\r\n    \r\n    # genres_as_string = data['genres'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n    # data_with_strings = pa.table({'genres': genres_as_string})\r\n    # grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n    # print(grouped)\r\n    \r\n    port = 50053\r\n    client = flight.FlightClient(f\"grpc+tcp://localhost:{port}\")\r\n    \r\n    main_table_name = 'TablesMethod_movies'\r\n    cast_table_name = 'TablesMethod_movies_cast'\r\n    genres_table_name = 'TablesMethod_movies_genres'\r\n    \r\n    reader = client.do_get(flight.Ticket(main_table_name.encode()))\r\n    main_data = reader.read_all()\r\n    \r\n    reader = client.do_get(flight.Ticket(cast_table_name.encode()))\r\n    cast_data = reader.read_all()\r\n    \r\n    reader = client.do_get(flight.Ticket(genres_table_name.encode()))\r\n    genres_data = reader.read_all()\r\n    \r\n    # print(main_data)\r\n    # print(cast_data)\r\n    # print(genres_data)\r\n    \r\n    # SELECTION\r\n    # first level query\r\n    ## to string\r\n    # print(main_data.select(['title']))\r\n    # ## to int\r\n    # print(main_data.select(['year']))\r\n    # # ## object from list \r\n    # # ### low level of nulls - first element of list\r\n    # print(cast_data)\r\n    \r\n    # grouped_table = cast_data.group_by('row_number')\r\n\r\n    # cast_row_number=cast_data['row_number']\r\n    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n    # aggregated_values = {}\r\n    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n    #     if row_number not in aggregated_values:\r\n    #         aggregated_values[row_number] = value_list\r\n    #     else:\r\n    #         aggregated_values[row_number].extend(value_list)\r\n\r\n    # first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n    # first_values_array = pa.array(first_values)\r\n    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n    # print(result_table)\r\n\r\n    # # ### medium level of nulls\r\n    # cast_row_number=cast_data['row_number']\r\n    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n    # aggregated_values = {}\r\n    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n    #     if row_number not in aggregated_values:\r\n    #         aggregated_values[row_number] = value_list\r\n    #     else:\r\n    #         aggregated_values[row_number].extend(value_list)\r\n\r\n    # tenth_values  = [value_list[9] if len(value_list) >= 10 else None for value_list in aggregated_values.values()]\r\n    # tenth_values_array  = pa.array(tenth_values )\r\n    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n    # print(result_table)\r\n    \r\n    # # ### high level of nulls - last element of list\r\n    # # print(data.select(['cast[58]']))\r\n    # cast_row_number=cast_data['row_number']\r\n    # split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n    # aggregated_values = {}\r\n    # for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n    #     if row_number not in aggregated_values:\r\n    #         aggregated_values[row_number] = value_list\r\n    #     else:\r\n    #         aggregated_values[row_number].extend(value_list)\r\n\r\n    # tenth_values  = [value_list[58] if len(value_list) > 58 else None for value_list in aggregated_values.values()]\r\n    # tenth_values_array  = pa.array(tenth_values )\r\n    # result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), tenth_values_array ], names=['row_number', 'first_value'])\r\n    # print(result_table)\r\n    \r\n\r\n    # # # FILTRES\r\n    # print(pc.filter(main_data, pc.greater(main_data.column('year'), 2000)))\r\n\r\n    # # #SORT\r\n    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"ascending\")])))\r\n    # # #SORT DESC\r\n    # print(pc.take(main_data,pc.sort_indices(main_data, sort_keys=[(\"title\", \"descending\")])))\r\n\r\n    # # #GROUP BY\r\n    # print(pa.TableGroupBy(main_data,'year'))\r\n\r\n    genres_row_number=genres_data['row_number']\r\n    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n    aggregated_values = {}\r\n    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n        if row_number not in aggregated_values:\r\n            aggregated_values[row_number] = value_list\r\n        else:\r\n            aggregated_values[row_number].extend(value_list)\r\n\r\n    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n    first_values_array = pa.array(first_values)\r\n    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n    print(result_table.group_by('first_value'))\r\n\r\n    genres_row_number = genres_data['row_number']\r\n    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n    aggregated_values = {}\r\n    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n        if row_number not in aggregated_values:\r\n            aggregated_values[row_number] = value_list\r\n        else:\r\n            aggregated_values[row_number].extend(value_list)\r\n    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n    first_values_array = pa.array(first_values)\r\n    second_values_array = pa.array(second_values)\r\n    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n    print(grouped_table)\r\n\r\n    cast_row_number=cast_data['row_number']\r\n    split_values = [v.split(', ') if v and v != \"null\" else [] for v in cast_data['value'].to_pylist()]\r\n    aggregated_values = {}\r\n    for row_number, value_list in zip(cast_row_number.to_pylist(), split_values):\r\n        if row_number not in aggregated_values:\r\n            aggregated_values[row_number] = value_list\r\n        else:\r\n            aggregated_values[row_number].extend(value_list)\r\n\r\n    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n    first_values_array = pa.array(first_values)\r\n    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n    print(result_table.group_by('first_value'))\r\n\r\n    # #AGGREGATE FUNCTION\r\n    print(pa.TableGroupBy(main_data,'year').aggregate([(\"year\", \"count\")]))\r\n    \r\n    genres_row_number=genres_data['row_number']\r\n    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n    aggregated_values = {}\r\n    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n        if row_number not in aggregated_values:\r\n            aggregated_values[row_number] = value_list\r\n        else:\r\n            aggregated_values[row_number].extend(value_list)\r\n\r\n    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n    first_values_array = pa.array(first_values)\r\n    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array], names=['row_number', 'first_value'])\r\n    print(result_table.group_by('first_value').aggregate([('first_value', \"count\")]))\r\n    \r\n    genres_row_number = genres_data['row_number']\r\n    split_values = [v.split(', ') if v and v != \"null\" else [] for v in genres_data['value'].to_pylist()]\r\n    aggregated_values = {}\r\n    for row_number, value_list in zip(genres_row_number.to_pylist(), split_values):\r\n        if row_number not in aggregated_values:\r\n            aggregated_values[row_number] = value_list\r\n        else:\r\n            aggregated_values[row_number].extend(value_list)\r\n    first_values = [value_list[0] if value_list else None for value_list in aggregated_values.values()]\r\n    second_values = [value_list[1] if len(value_list) > 1 else None for value_list in aggregated_values.values()]\r\n    first_values_array = pa.array(first_values)\r\n    second_values_array = pa.array(second_values)\r\n    result_table = pa.Table.from_arrays([pa.array(list(aggregated_values.keys())), first_values_array, second_values_array], names=['row_number', 'first_value', 'second_value'])\r\n    grouped_table = result_table.group_by(['first_value', 'second_value'])\r\n    print(grouped_table.aggregate([('first_value', \"count\"),('second_value', \"count\")]))\r\n\r\n\r\n    unique_row_numbers = pc.unique(genres_data['row_number'])\r\n    grouped_data = {'row_number': [], 'value': []}\r\n    for row_num in unique_row_numbers:\r\n        mask = pc.equal(genres_data['row_number'], row_num)\r\n        filtered_values = genres_data.filter(mask)['value'].to_pylist()\r\n        grouped_data['row_number'].append(row_num.as_py())\r\n        grouped_data['value'].append([val for val in filtered_values if val is not None])\r\n    grouped_table = pa.table(grouped_data)\r\n    \r\n    genres_as_string = grouped_table['value'].combine_chunks().cast(pa.list_(pa.string())).flatten().cast(pa.string()).cast(pa.utf8())\r\n    data_with_strings = pa.table({'genres': genres_as_string})\r\n    grouped = data_with_strings.group_by('genres').aggregate([('genres',\"count\")])\r\n    print(grouped)\r\n\r\nif __name__ == '__main__':\r\n    client_reddit()\r\n    # client_example()"
        }
    ]
}